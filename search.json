[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "There‚Äôs antimony, arsenic, aluminum, selenium."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Million Little Monomers",
    "section": "",
    "text": "Data Supply Chain\n\n\nIntroduction, definitions, and a breakfast insight\n\n\n\n\nData Supply Chain\n\n\nInsight Delivery\n\n\n\n\nGenerating insights from raw data and delivering insights to decision makers are two critical stages for creating value from data.\n\n\n\n\n\n\nApr 11, 2023\n\n\nLiqC\n\n\n\n\n\n\n  \n\n\n\n\nDecision-Driven Analyics\n\n\nLooking for a purpose for your data? Think decisions first.\n\n\n\n\nData Culture\n\n\nData Strategy\n\n\n\n\nAre you turning to data to confirm your beliefs, or are you truly exploring the possibilities?\n\n\n\n\n\n\nMar 14, 2023\n\n\nLiqC\n\n\n\n\n\n\n  \n\n\n\n\nQuarto: Back in Blog\n\n\nPublication-Grade Technical Communication\n\n\n\n\nHousekeeping\n\n\nHowto\n\n\nQuarto\n\n\n\n\nContext and path to adoption of the best scientific and publishing system of today\n\n\n\n\n\n\nMar 13, 2023\n\n\nLiqC\n\n\n\n\n\n\n  \n\n\n\n\nElements of Surprise\n\n\nAnd some polypropylene\n\n\n\n\nHello, World\n\n\nTables\n\n\nBokeh\n\n\n\n\nSomething else to get started.\n\n\n\n\n\n\nFeb 3, 2022\n\n\nLiqC\n\n\n\n\n\n\n  \n\n\n\n\nPolyethylene\n\n\nAnd a small periodic table\n\n\n\n\nHello, World\n\n\nTables\n\n\n\n\nSomething to get started.\n\n\n\n\n\n\nFeb 2, 2022\n\n\nLiqC\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/23/quarto-back-in-blog/index.html",
    "href": "posts/23/quarto-back-in-blog/index.html",
    "title": "Quarto: Back in Blog",
    "section": "",
    "text": "Many moons ago, I had a LiveJournal blog about fun times in a chemistry lab. It was my first attempt to put some thoughts together in a foreign language. Drawing molecules and silly commentary on the science of the day with I-Can-Has-Cheeseburger-style illustrations was the name of the game. Fast forward fifteen years‚Ä¶ I became a data analyst/engineer/scientist, and a lot of my thoughts are in or near code (python and friends). One thing did not change: I still enjoy drawing molecules.\n\n\n\n\n\nThere will be molecules!\n\n\nAnother thing that did not change: Wordpress is still one of the most popular platforms for just about everything on the web. But see, I want my blog to run my shiny 2023 code.\nI‚Äôve been looking for a solution that could serve as a platform and for my own thoughts, as well as something that could work as a knowledge management system in a corporate setting. If you spent any time on tech teams, you know that writing documentation is one of the eternal pain points. In data science, you often want to present your thoughts mixed together with code, most commonly in Jupyter notebooks. You also want nicely styled page layout and code blocks, and some support for content management (screenshots, images, videos). Over the years I‚Äôve been a part of data science/engineering teams in biotech, healthcare, and telecom, I haven‚Äôt seen a solution I liked. Chances are, if I worked at Google, I‚Äôd embrace markdown-driven publishing sooner.\n\n\nWhether you like or hate Jupyter notebooks, you have to admit that they are the vehicle for innovation around data. FastAI‚Äôs Jeremy Howard has probably taken Jupyter notebooks further than anyone: the entire 20K-stars deep learning library and the printed book that goes along with it were both created entirely in notebooks. He‚Äôs a fan of scientific journaling, the habit of documenting your thought process, and I like the idea as well. Writing in interactive notebooks allows your code and your thought process to coexist, so you can communicate to others and your future self not just what you did but why you did it.\n\n\n\nLiterate programming is a methodology that combines a programming language with a documentation language, thereby making programs more robust, more portable, more easily maintained, and arguably more fun to write than programs that are written only in a high-level language. The main idea is to treat a program as a piece of literature, addressed to human beings rather than to a computer.1\n\nOf course, problems begin when you attempt to build on somebody‚Äôs work in a notebook (environments ü§™), or check them into github, or build some kind of knowledge or analytics repository from notebooks. You have to make compromises.\n\n\n\nI first learned about Quarto from Jeremy Howard‚Äôs I Like Notebooks talk. From there I learned about FastAI‚Äôs nbdev and its documentation framework called fastpages. Around the same time, the creators of RStudio and RMarkdown, the company founded by JJ Allaire that is now known as Posit, released Quarto. The FastAI team recognized that Quarto supersedes what they were able to build to date, and decided to abandon their work and endorse Quarto. The fact that prominent practitioners from the R and Python worlds converged on one vehicle for insight delivery was enough for me to settle on Quarto.\n\nOne of the main ideas of Quarto is to help scientific communication take better advantage of the web while still not losing the focus on print. Another piece, which was a huge focus of the R community, is reproducibility. All your work should be in a computational document that runs top to bottom. Your figures, tables, and results are reproducibly made by code. Accurate, trustworthy computing of scientific results is the prime directive.2\n\n\n\n\nThe output of browser-native data exploration should end up in a browser-native habitat. Viewed as an HTML page that is decorated with care and attention to detail, your code and narrative are experienced in a very similar way to how the author first created it. With syntax highlighting, interactive plots, and codefolding, the output appeals to a range of audiences. Some may choose to read the TLDR and browse the figures. Some will play with the charts. Some will examine the code. The experience reminds me of a safari: the wildlife is as wild as it gets, and the visitor has lots of choices for how to interact with it. If some of the native functionality is removed, your notebook may be a zoo, or even in a circus. Live notebooks solutions (Binder, JupyterHub) remain slow and fragile. Standalone notebook files require you to fire up your own Jupyter (your execs won‚Äôt be doing that). Github-rendered notebooks lose output, and often fail to show up at all. There‚Äôs a fair chance that Github will eventually implement Quarto for showing notebooks.\n\n\n\nHere‚Äôs a list of features I‚Äôm loving. Quite far from discovering all of what Quarto has to offer.\n\nPreview the rendered page, with livereload.\nHTML output that does not suck. You may have tried save a notebook as HTML, which is done with nbconvert, and learned how clunky it is. Here, the conversion just works, looks great, and loads fast. All the interactive charts remain interactive (Altair, Bokeh, Plotly all work). The code blocks are easily portable, thanks to a copy button.\nOptions for comments.\nPublish with one command to Github Pages or Quarto‚Äôs own platform.\nYou can directly paste iframes code to embed special content (like the YouTube video above), giving you functionality similar to Notion.\nRich use of markdown. Quarto‚Äôs VSCode extension will even render the Quarto-native .qmd file as a notebook.\nThe ability to select different execution kernels (bring your own requirements.txt or poetry.lock). Quarto allows you to select kernels, which are just JSON files pointed at the right interpreter. Assuming you‚Äôve got ipykernel in your package, run python -m ipykernel install --user --name my_env to link the python executable to my_env kernel; check jupyter kernelspec list to find the files and verify.\nOption for self-contained HTML output files with all content, stylesheets, and scripts embedded.\nChoice of themes and layouts.\nBring your own CSS for extra customization.\n\n\n\n\n\n\n\n/* CSS to indent and justify */\nsection &gt; p {\n    text-indent: 1em;\n    text-align: justify;\n}"
  },
  {
    "objectID": "posts/23/quarto-back-in-blog/index.html#the-fate-of-notebooks",
    "href": "posts/23/quarto-back-in-blog/index.html#the-fate-of-notebooks",
    "title": "Quarto: Back in Blog",
    "section": "",
    "text": "Whether you like or hate Jupyter notebooks, you have to admit that they are the vehicle for innovation around data. FastAI‚Äôs Jeremy Howard has probably taken Jupyter notebooks further than anyone: the entire 20K-stars deep learning library and the printed book that goes along with it were both created entirely in notebooks. He‚Äôs a fan of scientific journaling, the habit of documenting your thought process, and I like the idea as well. Writing in interactive notebooks allows your code and your thought process to coexist, so you can communicate to others and your future self not just what you did but why you did it.\n\n\n\nLiterate programming is a methodology that combines a programming language with a documentation language, thereby making programs more robust, more portable, more easily maintained, and arguably more fun to write than programs that are written only in a high-level language. The main idea is to treat a program as a piece of literature, addressed to human beings rather than to a computer.1\n\nOf course, problems begin when you attempt to build on somebody‚Äôs work in a notebook (environments ü§™), or check them into github, or build some kind of knowledge or analytics repository from notebooks. You have to make compromises."
  },
  {
    "objectID": "posts/23/quarto-back-in-blog/index.html#enter-quarto",
    "href": "posts/23/quarto-back-in-blog/index.html#enter-quarto",
    "title": "Quarto: Back in Blog",
    "section": "",
    "text": "I first learned about Quarto from Jeremy Howard‚Äôs I Like Notebooks talk. From there I learned about FastAI‚Äôs nbdev and its documentation framework called fastpages. Around the same time, the creators of RStudio and RMarkdown, the company founded by JJ Allaire that is now known as Posit, released Quarto. The FastAI team recognized that Quarto supersedes what they were able to build to date, and decided to abandon their work and endorse Quarto. The fact that prominent practitioners from the R and Python worlds converged on one vehicle for insight delivery was enough for me to settle on Quarto.\n\nOne of the main ideas of Quarto is to help scientific communication take better advantage of the web while still not losing the focus on print. Another piece, which was a huge focus of the R community, is reproducibility. All your work should be in a computational document that runs top to bottom. Your figures, tables, and results are reproducibly made by code. Accurate, trustworthy computing of scientific results is the prime directive.2"
  },
  {
    "objectID": "posts/23/quarto-back-in-blog/index.html#analysis-safari",
    "href": "posts/23/quarto-back-in-blog/index.html#analysis-safari",
    "title": "Quarto: Back in Blog",
    "section": "",
    "text": "The output of browser-native data exploration should end up in a browser-native habitat. Viewed as an HTML page that is decorated with care and attention to detail, your code and narrative are experienced in a very similar way to how the author first created it. With syntax highlighting, interactive plots, and codefolding, the output appeals to a range of audiences. Some may choose to read the TLDR and browse the figures. Some will play with the charts. Some will examine the code. The experience reminds me of a safari: the wildlife is as wild as it gets, and the visitor has lots of choices for how to interact with it. If some of the native functionality is removed, your notebook may be a zoo, or even in a circus. Live notebooks solutions (Binder, JupyterHub) remain slow and fragile. Standalone notebook files require you to fire up your own Jupyter (your execs won‚Äôt be doing that). Github-rendered notebooks lose output, and often fail to show up at all. There‚Äôs a fair chance that Github will eventually implement Quarto for showing notebooks."
  },
  {
    "objectID": "posts/23/quarto-back-in-blog/index.html#features-abound",
    "href": "posts/23/quarto-back-in-blog/index.html#features-abound",
    "title": "Quarto: Back in Blog",
    "section": "",
    "text": "Here‚Äôs a list of features I‚Äôm loving. Quite far from discovering all of what Quarto has to offer.\n\nPreview the rendered page, with livereload.\nHTML output that does not suck. You may have tried save a notebook as HTML, which is done with nbconvert, and learned how clunky it is. Here, the conversion just works, looks great, and loads fast. All the interactive charts remain interactive (Altair, Bokeh, Plotly all work). The code blocks are easily portable, thanks to a copy button.\nOptions for comments.\nPublish with one command to Github Pages or Quarto‚Äôs own platform.\nYou can directly paste iframes code to embed special content (like the YouTube video above), giving you functionality similar to Notion.\nRich use of markdown. Quarto‚Äôs VSCode extension will even render the Quarto-native .qmd file as a notebook.\nThe ability to select different execution kernels (bring your own requirements.txt or poetry.lock). Quarto allows you to select kernels, which are just JSON files pointed at the right interpreter. Assuming you‚Äôve got ipykernel in your package, run python -m ipykernel install --user --name my_env to link the python executable to my_env kernel; check jupyter kernelspec list to find the files and verify.\nOption for self-contained HTML output files with all content, stylesheets, and scripts embedded.\nChoice of themes and layouts.\nBring your own CSS for extra customization.\n\n\n\n\n\n\n\n/* CSS to indent and justify */\nsection &gt; p {\n    text-indent: 1em;\n    text-align: justify;\n}"
  },
  {
    "objectID": "posts/23/quarto-back-in-blog/index.html#footnotes",
    "href": "posts/23/quarto-back-in-blog/index.html#footnotes",
    "title": "Quarto: Back in Blog",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDonald Knuth‚Ü©Ô∏é\nJeremy Howard + JJ Allaire two-way AMA‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/23/decision-driven-analytics/index.html",
    "href": "posts/23/decision-driven-analytics/index.html",
    "title": "Decision-Driven Analyics",
    "section": "",
    "text": "Decision-Driven Analytics\nData-driven decision-making has become a common practice in modern companies. Despite the good intentions, the outcomes of analytics initiatives are often disappointing. The problem lies in the habit of treating data as a hammer in search of a nail. Time and again, the pre-ordained decision has already been made‚Äîperhaps based on intuition, or on what‚Äôs been sold to customers/investors, or some other desired view of the reality. Now the leadership turns to data for a nod. We must move forward and make progress, but sure, we‚Äôll take a quick look at what we know.\nThe result? Preexisting beliefs, biases, and incentives are reinforced. Though important data gaps may be exposed, investing in better data or better data analysis never gets prioritized, because the end product of the data supply chain (the decision) is already at hand.\nBart De Langhe and Stefano Puntoni call for replacing data-driven decision-making with decision-driven analytics. It starts from a proper definition of the decision that needs to be made and the data that is needed to support or reject that decision.\nTo shift to decision-driven data analytics, a company should start by identifying the business‚Äôs key decisions and the people who make them, and finding data for a purpose. Leaders can take three steps:\n\nForm a narrow consideration set of alternative courses of action,\nIdentify or gather the data needed to figure out which course of action is best\nChoose the best course of action.\n\nAs you retrospect on the decision that was made, this process can help separate the quality of the outcome from the quality of the decision.\n\n‚ÄúDecision-driven data analytics emphasizes the importance of asking questions. This approach draws attention to unknowns and the value of additional data collection and analysis. Companies and leaders who take this approach benefit by ensuring that analytics initiatives are tied to action, are focused on answering the questions that matter, and challenge rather than bolster executives‚Äô beliefs about how the world works.‚Äù\n\nRead the paper, watch the interview with MIT Management Review.\nAlso published on: LinkedIn"
  },
  {
    "objectID": "posts/23/elements-of-surprise/index.html",
    "href": "posts/23/elements-of-surprise/index.html",
    "title": "Elements of Surprise",
    "section": "",
    "text": "A surprising periodic table of elements.\n\n\nShow the code\ndef elements_of_surprise():\n    \"\"\"Adapted from https://docs.bokeh.org/en/latest/docs/gallery/periodic.html\"\"\"\n    \n    from bokeh.sampledata.periodic_table import elements\n    df = elements.copy()\n\n    # element of surprise\n    df[[\"name\",\"symbol\"]] = df[[\"name\",\"symbol\"]].sample(frac=1).values\n\n    # plotting\n    from bokeh.embed import file_html\n    from bokeh.plotting import figure\n    from bokeh.resources import CDN\n    from bokeh.transform import dodge, factor_cmap\n    from IPython.display import HTML\n\n    periods = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\"]\n    groups = [str(x) for x in range(1, 19)]\n\n    df = elements.copy()\n\n    #element of surprise\n    df[[\"name\",\"symbol\"]] = df[[\"name\",\"symbol\"]].sample(frac=1).values\n\n    df[\"atomic mass\"] = df[\"atomic mass\"].astype(str).apply(lambda x: x[:8])\n    df[\"group\"] = df[\"group\"].astype(str)\n    df[\"period\"] = [periods[x-1] for x in df.period]\n    df = df[df.group != \"-\"]\n\n    cmap = {\n        \"alkali metal\"         : \"#a6cee3\",\n        \"alkaline earth metal\" : \"#1f78b4\",\n        \"metal\"                : \"#d93b43\",\n        \"halogen\"              : \"#999d9a\",\n        \"metalloid\"            : \"#e08d49\",\n        \"noble gas\"            : \"#eaeaea\",\n        \"nonmetal\"             : \"#f1d4Af\",\n        \"transition metal\"     : \"#599d7A\",\n    }\n\n    TOOLTIPS = [\n        (\"Name\", \"@name\"),\n        (\"Atomic number\", \"@{atomic number}\"),\n        (\"Atomic mass\", \"@{atomic mass}\"),\n        (\"Type\", \"@metal\"),\n        (\"CPK color\", \"$color[hex, swatch]:CPK\"),\n        (\"Electronic configuration\", \"@{electronic configuration}\"),\n    ]\n\n    p = figure(title=\"Periodic Table\", width=1200, height=500,\n            x_range=groups, y_range=list(reversed(periods)),\n            tools=\"hover\", toolbar_location=None, tooltips=TOOLTIPS)\n\n    r = p.rect(\"group\", \"period\", 0.95, 0.95, source=df, fill_alpha=0.6, legend_field=\"metal\",\n            color=factor_cmap('metal', palette=list(cmap.values()), factors=list(cmap.keys())))\n\n    text_props = dict(source=df, text_align=\"left\", text_baseline=\"middle\")\n\n    x = dodge(\"group\", -0.4, range=p.x_range)\n\n    p.text(x=x, y=dodge(\"period\", 0.05, range=p.y_range), text=\"symbol\",\n        text_font_size=\"18px\", text_font_style=\"bold\", **text_props)\n\n    p.text(x=x, y=dodge(\"period\", 0.3, range=p.y_range), text=\"atomic number\",\n        text_font_size=\"14px\", **text_props)\n\n    p.text(x=x, y=dodge(\"period\", -0.35, range=p.y_range), text=\"name\",\n        text_font_size=\"10px\", **text_props)\n\n    p.text(x=x, y=dodge(\"period\", -0.2, range=p.y_range), text=\"atomic mass\",\n        text_font_size=\"10px\", **text_props)\n\n    p.outline_line_color = None\n    p.grid.grid_line_color = None\n    p.axis.axis_line_color = None\n    p.axis.major_tick_line_color = None\n    p.axis.major_label_standoff = 0\n    p.legend.orientation = \"horizontal\"\n    p.legend.location =\"top_center\"\n    p.hover.renderers = [r] # only hover element boxes\n\n    html = file_html(p, CDN, \"Periodic Table\")\n    return HTML(html)\n\n\n\nelements_of_surprise()\n\n\n\n\n  \n    \n    Periodic Table\n\n    \n    \n  \n  \n    \n  \n    \n    \n  \n\n\n\n\n\n\nCH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 42 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r, 'r-')\nax.set_rticks([0, 1, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure¬†1: A line plot on a polar axis"
  },
  {
    "objectID": "posts/23/elements-of-surprise/index.html#polypropylene",
    "href": "posts/23/elements-of-surprise/index.html#polypropylene",
    "title": "Elements of Surprise",
    "section": "",
    "text": "CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2 CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2CH(CH3)CH2"
  },
  {
    "objectID": "posts/23/elements-of-surprise/index.html#polymerplotlib",
    "href": "posts/23/elements-of-surprise/index.html#polymerplotlib",
    "title": "Elements of Surprise",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 42 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r, 'r-')\nax.set_rticks([0, 1, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure¬†1: A line plot on a polar axis"
  },
  {
    "objectID": "posts/23/data-supply-chain-breakfast/index.html",
    "href": "posts/23/data-supply-chain-breakfast/index.html",
    "title": "Data Supply Chain",
    "section": "",
    "text": "What if I told you that there is no data science?\nOr data analytics or engineering?\nJust logistics.\nAll these lines of work are in service of data supply chain.\nSupply chains haven‚Äôt been on our minds much, until the COVID pandemic brought along issues with getting all kinds of stuff we take for granted. We‚Äôve learned to associate supply chains with the movement of physical goods. Indeed, it‚Äôs been the case for millenia: when people found something valuable, others found ways to get it. Did you notice a bit of an implied data exchange in the previous sentence? Merchants need a way to tell buyers what they have, and collect the data on what they need. Data has always played a role in supply chains. Sometimes just this data is precious. In the spring of 2020 I was working in a hospital supply chain, and ‚ÄúWHO HAS MASKS?‚Äù was a multi-million dollar question.\nLet‚Äôs take a closer look at supply chains built around data, and define the data supply chain while we‚Äôre at it. Data supply chain is a sequence of sociotechnical processes for building and distributing data products. There are two major steps in a data supply chain. We collect, enhance, and analyze data to derive insights. We use insights to make decisions. Much like in the physical goods world, smart use of technology confers a competitive advantage.\n\n\n\nData Supply Chain: a sequence of sociotechnical processes for building and distributing data products\n\n\nFully human, as well as fully automated data supply chains are all around us. Upon collecting some data from your fridge and pantry, the insights, decisions, and actions that will make food appear on your table tonight will be mostly made by you (though this is changing). In contrast, your thermostat makes decisions to cool or heat your home all by itself, based on insights derived from processing data from temperature sensors. You can certainly find similar examples in organizations, but if you attempt to trace the lifecycle of some recent decisions, you might observe that the extent of human involvement increases along with product maturity. The specifics of how we handle the first step are mainly technical (think scientific instruments, data pipelines, databases, dashboards). The second step is a lot more about people (think meetings, presentations, publications).\nWhen we view the process of value creation from data from the lens of the data supply chain, it makes perfect sense why we care about data quality and governance, as well as technology required to process raw data. If you run a restaurant, it would be unwise to make breakfast from rotten eggs and rusty cookware. But you also need good servers to deliver the food and help the guests decide what to eat.\nHow hard can it be to not bring rotten eggs to the kitchen?\nHow hard can it be to ‚Äúserve‚Äù an insight?\nWhich of the two steps have you found more challenging in your work?\n#datasupplychain #insightdelivery #datastrategy"
  },
  {
    "objectID": "posts/23/polyethylene/index.html",
    "href": "posts/23/polyethylene/index.html",
    "title": "Polyethylene",
    "section": "",
    "text": "CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2 CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2 CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2 CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2 CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2 CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2 CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2CH2\n\n\n| Period  | Group 1 | Group 2 | Group 17 | Group 18 |\n|---------|:--------|--------:|:--------:|:--------:|\n| 1       | H       |         |          | He       |\n| 2       | Li      | Be      | F        | Ne       |"
  },
  {
    "objectID": "posts/23/polyethylene/index.html#small-but-periodic",
    "href": "posts/23/polyethylene/index.html#small-but-periodic",
    "title": "Polyethylene",
    "section": "",
    "text": "| Period  | Group 1 | Group 2 | Group 17 | Group 18 |\n|---------|:--------|--------:|:--------:|:--------:|\n| 1       | H       |         |          | He       |\n| 2       | Li      | Be      | F        | Ne       |"
  }
]